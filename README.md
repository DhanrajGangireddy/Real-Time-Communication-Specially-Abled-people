# Real-Time-Communication-Specially-Abled-people
The machine learning model used for recognition was trained on a dataset of hand gesture images representing different alphabets. The training data was split into training and testing sets, and the model was trained using the training set to learn the patterns in the images. The trained model's accuracy was evaluated using the testing set to ensure its performance on unseen data.Now, users can interact with the web application by showing their hand gestures in front of a camera. 
 The project involves training a machine learning model on hand gesture images, testing its accuracy on unseen data, and creating a real-time web application that captures video frames from the camera, recognizes the hand gestures using the trained model, and streams the results back to the user in real-time.
